
fps: 30
sr: 16000 

log_iter: 125 # How often do you want to log the training stats
eval_iter: 1000 # How often do you want to eval and save a checkpoint
# data options
num_workers: 8
batch_size: 64 # batch size


# optimization options
max_epochs: 500
#max_iters: 500000
ngpus: 1
momentum: 0.9 # momentum
weight_decay: 0.05 # weight decay
betas: [0.9, 0.999] # Adam parameter
init: kaiming # initialization [gaussian/kaiming/xavier/orthogonal]
lr: 0.001 # initial learning rate
lr_policy: step # learning rate scheduler
gamma: 0.5 # how much to decay learning rate
step_size: 20000 # how often to decay learning rate

## model options
#model:
#  embed_len: 90  # len_clip, position encoding
#  audio_size: [40, 5]  # align with (num_mels, mel_step_size)
#  nhead: 4
#  num_decoder_layers: 4
#  dim_feedforward: 2048
#  dropout: 0.1
#  activation: "relu"
#  normalize_before: False
#  return_intermediate_dec: False
#  upper_face3d_indices: [6, 8, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37,
#                         38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]
#  lower_face3d_indices: [0, 1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14]  # fmt: on
#  network_type: "TransformerDecoder"
#  dynamic_K: 8
#  dynamic_ratio: 4

# model options
model:
  embed_len: 90 #90  # len_clip, position encoding
  audio_size: [40, 5]  # align with (num_mels, mel_step_size)
  d_init: 64
  nhead: 4
  num_encoder_layers: 2
  num_decoder_layers: 2
  dim_feedforward: 2048
  dropout: 0.1
  activation: "relu"
  batch_first: True
  upper_face3d_indices: [6, 8, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37,
                         38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]
  lower_face3d_indices: [0, 1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14]  # fmt: on
